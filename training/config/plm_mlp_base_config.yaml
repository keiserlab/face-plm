# Configuration for Hydra
hydra:
  run:
    dir: /tmp/hydra
  job:
    chdir: false

train_config:
  _target_: adk_dl.utils.TrainConfig
  batch_size: 64
  learning_rate: 1e-3
  num_workers: 0
  profiler: simple
  gpu_num: 0
  max_epoch_number: 2000
  warmup_epochs: 50

lr_config:
  _target_: adk_dl.utils.HyperParameterScheduler
  train_config: ${train_config}
  final_value: 1e-6
  warmup_initial_value: 1e-5
  base_value: 1e-4
  warmup_epochs: ${train_config.warmup_epochs}

encoder_config:
  _target_: adk_dl.models.FeedForwardEncoder
  hidden_dim: 768
  hidden_layers: 2
  input_dim: 1280

taskhead_config:
  _target_: adk_dl.models.RegressionHead
  input_dim: ${encoder_config.hidden_dim}

loss_config:
  _target_: torch.nn.MSELoss

wandb_config:
  _target_: adk_dl.utils.WandbRunConfig
  project: adk_deep_learning
  run_name: generic_plm_mlp

model_config:
  _target_: adk_dl.models.LightningModel
  optimizer:  "Adam"
  wd: 0.00
  lr_scheduler: ${lr_config}
  encoder: ${encoder_config}
  task_head: ${taskhead_config}
  loss_func: ${loss_config}

  