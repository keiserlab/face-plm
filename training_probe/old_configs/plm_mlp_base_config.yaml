# Configuration for Hydra
hydra:
  run:
    dir: /tmp/hydra
  job:
    chdir: false

defaults:
  - wandb_config: base_wandb

train_config:
  _target_: face_plm.probes.utils.TrainConfig
  batch_size: 64
  learning_rate: 1e-3
  num_workers: 0
  profiler: simple
  gpu_num: 0
  max_epoch_number: 2000
  warmup_epochs: 50

lr_config:
  _target_: face_plm.probes.utils.HyperParameterScheduler
  train_config: ${train_config}
  final_value: 1e-6
  warmup_initial_value: 1e-5
  base_value: 1e-4
  warmup_epochs: ${train_config.warmup_epochs}

encoder_config:
  _target_: face_plm.probes.models.FeedForwardEncoder
  hidden_dim: 768
  hidden_layers: 2
  input_dim: 1280

taskhead_config:
  _target_: face_plm.probes.models.RegressionHead
  input_dim: ${encoder_config.hidden_dim}

loss_config:
  _target_: torch.nn.MSELoss

model_config:
  _target_: face_plm.probes.models.LightningModel
  optimizer: "Adam"
  wd: 0.00
  lr_scheduler: ${lr_config}
  encoder: ${encoder_config}
  task_head: ${taskhead_config}
  loss_func: ${loss_config}

  